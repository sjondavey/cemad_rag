from regulations_rag.corpus_chat import CorpusChat
from regulations_rag.rerank import RerankAlgos
import copy

import logging
logger = logging.getLogger(__name__)
# Create custom log levels for the really detailed logs
DEV_LEVEL = 15
ANALYSIS_LEVEL = 25
logging.addLevelName(DEV_LEVEL, 'DEV')       
logging.addLevelName(ANALYSIS_LEVEL, 'ANALYSIS')       

"""  
I only need this class to implement the workflow hook
"""
class CorpusChatCEMAD(CorpusChat):
    def __init__(self, 
                 openai_client, 
                 embedding_parameters,
                 chat_parameters,
                 corpus_index,
                 rerank_algo = RerankAlgos.NONE,   
                 user_name_for_logging = 'test_user'): 
        super().__init__(openai_client, embedding_parameters, chat_parameters, corpus_index, rerank_algo, user_name_for_logging)

    
    
    """ 
    returns workflow_triggered, df_definitions, df_search_sections
    """
    def execute_workflow(self, workflow_triggered, user_content):
        if workflow_triggered == "documentation":
            #raise NotImplementedError()
            user_content = self.enrich_user_request_for_documentation(user_content, self.messages_without_rag)
            workflow_triggered, df_definitions, df_search_sections = self.similarity_search(user_content)
            return workflow_triggered, df_definitions, df_search_sections

        raise NotImplementedError()

    def enrich_user_request_for_documentation(self, user_content, messages_without_rag, model_to_use="gpt-4o"):
        """
        Enhances a user's request for documentation based on the conversation history. It constructs a standalone request
        for documentation, utilizing the most recent conversation history to formulate a question that specifies what documentation
        is required.

        Parameters:
        - user_content (str): The latest user content to be used for generating documentation requests.
        - messages_without_rag (list): A list of message dictionaries that exclude RAG content, to be used as conversation history.
        - model_to_use (str, optional): Specifies the AI model to use for generating the documentation request. Defaults to "gpt-3.5-turbo".

        Returns:
        - str: The enhanced documentation request generated by the model.
        """
        logger.info("Enriching user request for documentation based on conversation history.")

        # Preparing the initial system message to guide the model in request generation
        system_content = "You are assisting a user to construct a stand alone request for documentation from a conversation. \
At the end of the conversation they have asked a question about the documentation they require. Your job is to review the conversation history and to respond with this question \
'What documentation is required as evidence for ...' where you need to replace the ellipses with a short description of the most recent conversation history. Try to keep the question short and general."
        
        # Create a complete list of messages excluding the system message
        messages_copy = copy.deepcopy(messages_without_rag)
        messages_copy.append({'role': 'user', 'content': user_content})
        
        # Truncate messages list to meet a specific token limit and ensure there is space for the system message
        system_message={'role': 'system', 'content': system_content}
        truncated_messages = self._truncate_message_list([system_message], messages_copy, token_limit=3500)
        # NOTE, the truncated_messages will now contain the system message

        # Generate the enhanced documentation request using the specified AI model
        response = self.openai_client.chat.completions.create(
            model=model_to_use,
            temperature=1.0,
            max_tokens=200,
            messages=truncated_messages
        )

        # Extract the initial response and log information for review
        initial_response = response.choices[0].message.content
        logger.info(f"{self.user_name} original question: {user_content}")
        logger.info(f"System enhanced question: {initial_response}")

        # Check if the response starts as expected; log a warning if not
        if not initial_response.startswith('What documentation is required as evidence for'):
            logger.warning("The function did not enrich the user request for documentation as expected, which may create problems.")

        return initial_response